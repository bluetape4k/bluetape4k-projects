# 가드레일 강화

> 이 문서는 Claude 공식 문서에서 해당 페이지가 아직 공개되지 않아 기본 구조만 제공합니다.

## 개요

가드레일은 AI 에이전트가 안전하고 의도된 범위 내에서 작동하도록 보장하는 메커니즘입니다.

## 가드레일 유형

### 1. 입력 가드레일

- 프롬프트 인젝션 방지
- 악의적인 입력 필터링
- 입력 유효성 검사

### 2. 출력 가드레일

- 민감 정보 필터링
- 유해 콘텐츠 차단
- 형식 준수 확인

### 3. 행동 가드레일

- 도구 사용 제한
- 파일 시스템 접근 제어
- 네트워크 요청 제한

### 4. 리소스 가드레일

- 토큰 사용량 제한
- 실행 시간 제한
- API 호출 제한

## 구현 전략

### 권한 관리

```python
options = ClaudeAgentOptions(
    allowed_tools=["Read", "Glob", "Grep"],  # 읽기 전용
    permission_mode="bypassPermissions"
)
```

### 훅을 통한 검증

```python
hooks={
    "PreToolUse": [{
        "matcher": "Bash",
        "hooks": [{
            "type": "command",
            "command": "validate_command.sh"
        }]
    }]
}
```

### 도구 필터링

특정 도구만 허용하거나 특정 도구를 차단하여 에이전트의 능력을 제한

## 모범 사례

1. **최소 권한 원칙**: 필요한 최소한의 권한만 부여
2. **계층적 검증**: 여러 레벨에서 검증 수행
3. **실패 안전**: 검증 실패 시 안전한 기본값으로 폴백
4. **로깅 및 감사**: 모든 작업을 기록하여 추적 가능
5. **정기적 검토**: 가드레일 효과성 주기적 평가

## 보안 고려사항

### 프롬프트 인젝션 방어

- 사용자 입력과 시스템 지침 분리
- XML 태그를 사용한 구조화
- 입력 이스케이프 처리

### 데이터 보호

- 민감 데이터 마스킹
- 출력 스크러빙
- 접근 제어 적용

### 코드 실행 안전

- 샌드박스 환경 사용
- 실행 시간 제한
- 리소스 쿼터 적용
